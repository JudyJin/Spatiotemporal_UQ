{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "import sys\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import us as usStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def days(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%m/%d/%Y\")\n",
    "    d2 = datetime.strptime(d2, \"%m/%d/%Y\")\n",
    "    return abs((d2 - d1).days)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    "# x,y = shuffle_in_unison(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groundtruth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 50)\n"
     ]
    }
   ],
   "source": [
    "dfg = pd.read_csv('data/time_series_covid19_deaths_US.csv')\n",
    "dfg1 = dfg.drop(['UID', 'iso2','iso3','code3','FIPS','Admin2','Country_Region','Lat','Long_','Combined_Key','Population'], axis=1)\n",
    "dfg2 = dfg1.groupby(dfg1['Province_State']).aggregate('sum')\n",
    "dfg2 = dfg2.drop(['District of Columbia','American Samoa','Guam','Northern Mariana Islands','Virgin Islands','Puerto Rico','Grand Princess','Diamond Princess'],axis = 0)\n",
    "\n",
    "groundtruth = dfg2.diff(axis=1).to_numpy().T[days('01/22/2020','05/23/2020'):]\n",
    "# savetxt('./new_oneweek_ahead/groundtruth.csv', groundtruth, delimiter=',')\n",
    "print(groundtruth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 50)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/gleam_mw_1_wk_ahead_ts_daily.csv')\n",
    "df = df.drop(['last_ground_truth_date'], axis=1)\n",
    "df1 = df.sort_values(by=['target_date', 'state_name'])\n",
    "df2 = df1.drop_duplicates(subset=['target_date'])\n",
    "df3 = df1.drop_duplicates(subset=['state_name'])\n",
    "\n",
    "time_length = days('05/24/2020','12/05/2020')\n",
    "state_length = 50\n",
    "\n",
    "pred_week1 = np.zeros([time_length,state_length])\n",
    "\n",
    "list1 = list(df2['target_date'][21:])\n",
    "list2 = list(df3['state_name'])\n",
    "\n",
    "\n",
    "for id1,i in enumerate (list1):\n",
    "    df4 = df.loc[df['target_date'] == i]\n",
    "    for id2,j in enumerate (list2):\n",
    "        df5 = df4.loc[df4['state_name'] == j]\n",
    "        pred_week1[id1,id2] = df5['Death_mean_weighted']\n",
    "print(pred_week1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 50)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/gleam_mw_2_wk_ahead_ts_daily.csv')\n",
    "df = df.drop(['last_ground_truth_date'], axis=1)\n",
    "df1 = df.sort_values(by=['target_date', 'state_name'])\n",
    "df2 = df1.drop_duplicates(subset=['target_date'])\n",
    "df3 = df1.drop_duplicates(subset=['state_name'])\n",
    "\n",
    "time_length = days('05/24/2020','12/05/2020')\n",
    "state_length = 50\n",
    "\n",
    "pred_week2 = np.zeros([time_length,state_length])\n",
    "\n",
    "list1 = list(df2['target_date'][14:-7])\n",
    "list2 = list(df3['state_name'])\n",
    "\n",
    "\n",
    "for id1,i in enumerate (list1):\n",
    "    df4 = df.loc[df['target_date'] == i]\n",
    "    for id2,j in enumerate (list2):\n",
    "        df5 = df4.loc[df4['state_name'] == j]\n",
    "        pred_week2[id1,id2] = df5['Death_mean_weighted']\n",
    "print(pred_week2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 50)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/gleam_mw_3_wk_ahead_ts_daily.csv')\n",
    "df = df.drop(['last_ground_truth_date'], axis=1)\n",
    "df1 = df.sort_values(by=['target_date', 'state_name'])\n",
    "df2 = df1.drop_duplicates(subset=['target_date'])\n",
    "df3 = df1.drop_duplicates(subset=['state_name'])\n",
    "\n",
    "time_length = days('05/24/2020','12/05/2020')\n",
    "state_length = 50\n",
    "\n",
    "pred_week3 = np.zeros([time_length,state_length])\n",
    "\n",
    "list1 = list(df2['target_date'][7:-14])\n",
    "list2 = list(df3['state_name'])\n",
    "\n",
    "\n",
    "for id1,i in enumerate (list1):\n",
    "    df4 = df.loc[df['target_date'] == i]\n",
    "    for id2,j in enumerate (list2):\n",
    "        df5 = df4.loc[df4['state_name'] == j]\n",
    "        pred_week3[id1,id2] = df5['Death_mean_weighted']\n",
    "print(pred_week3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 50)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/gleam_mw_4_wk_ahead_ts_daily.csv')\n",
    "df = df.drop(['last_ground_truth_date'], axis=1)\n",
    "df1 = df.sort_values(by=['target_date', 'state_name'])\n",
    "df2 = df1.drop_duplicates(subset=['target_date'])\n",
    "df3 = df1.drop_duplicates(subset=['state_name'])\n",
    "\n",
    "time_length = days('05/24/2020','12/05/2020')\n",
    "state_length = 50\n",
    "\n",
    "pred_week4 = np.zeros([time_length,state_length])\n",
    "\n",
    "list1 = list(df2['target_date'][:-21])\n",
    "list2 = list(df3['state_name'])\n",
    "\n",
    "\n",
    "for id1,i in enumerate (list1):\n",
    "    df4 = df.loc[df['target_date'] == i]\n",
    "    for id2,j in enumerate (list2):\n",
    "        df5 = df4.loc[df4['state_name'] == j]\n",
    "        pred_week4[id1,id2] = df5['Death_mean_weighted']\n",
    "print(pred_week4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 196, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.stack([pred_week1,pred_week2,pred_week3,pred_week4],axis=0)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get residual (avg groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "residual = pred - groundtruth\n",
    "residual_trans = residual.transpose(1,2,0)\n",
    "print(residual_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6 -5 -4 -3 -2 -1  0]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "x_offsets = np.sort(np.concatenate((np.arange(-6, 1, 1),)))\n",
    "print(x_offsets)\n",
    "y_offsets = np.array([7])\n",
    "print(y_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  1.   1.   1. ...   1.   1.   1.]\n",
      " [  2.   2.   2. ...   2.   2.   2.]\n",
      " ...\n",
      " [193. 193. 193. ... 193. 193. 193.]\n",
      " [194. 194. 194. ... 194. 194. 194.]\n",
      " [195. 195. 195. ... 195. 195. 195.]]\n"
     ]
    }
   ],
   "source": [
    "#x data\n",
    "\n",
    "x_num_samples, x_num_nodes = 196, 50\n",
    "x_data = residual_trans\n",
    "# x_data = residual.transpose(1,2,0)\n",
    "\n",
    "x_day = list(range(0,x_num_samples))\n",
    "\n",
    "x_day = np.tile(x_day, [1, x_num_nodes, 1]).transpose((2, 1, 0))\n",
    "x_data = np.concatenate([x_data,x_day], axis=-1)\n",
    "print(x_data[:,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 7, 50, 5)\n",
      "(1, 7, 50, 5)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "# t is the index of the last observation.\n",
    "min_t = abs(min(x_offsets))\n",
    "for t in range(min_t,x_data.shape[0]):\n",
    "    x_t = x_data[t+ x_offsets]\n",
    "    x.append(x_t)\n",
    "x1 = np.stack(x, axis=0)[:162]\n",
    "\n",
    "x_test = np.stack(x, axis=0)[days('05/30/2020','12/05/2020')-1:days('05/30/2020','12/05/2020')]\n",
    "\n",
    "\n",
    "\n",
    "print(x1.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.0\n",
      "167.0\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0,6,0,4])\n",
    "print(x1[-1,6,0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 50, 4)\n",
      "(162, 4, 50, 1)\n",
      "(1, 4, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "#y data\n",
    "\n",
    "list5 = []\n",
    "for i in range (days('05/24/2020','12/05/2020')-6):\n",
    "    residual_sum7 = np.sum((residual[:,i:i+7]),axis=1)\n",
    "    list5.append(residual_sum7)\n",
    "\n",
    "residual_sum = np.stack(list5,axis =1)\n",
    "residual_sum_trans = residual_sum.transpose(1,2,0)\n",
    "print(residual_sum_trans.shape)\n",
    "\n",
    "y_data = np.stack([residual_sum_trans[7:7+162,:,0],residual_sum_trans[7*2:7*2+162,:,1],\n",
    "                        residual_sum_trans[7*3:7*3+162,:,2],residual_sum_trans[7*4:7*4+162,:,3]],axis=-1)\n",
    "\n",
    "y1 = np.expand_dims(y_data, axis =1)\n",
    "y1 = y1.transpose(0,3,2,1)\n",
    "\n",
    "\n",
    "y_test = np.zeros([1,4,50,1])\n",
    "\n",
    "print(y1.shape)\n",
    "print(y_test.shape)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 50, 5)\n",
      "174.0\n"
     ]
    }
   ],
   "source": [
    "y_num_nodes = 50\n",
    "y_day = np.tile(np.arange(6,6+residual_sum_trans.shape[0]),(1,y_num_nodes,1)).transpose(2,1,0)\n",
    "y_new = np.concatenate((residual_sum_trans,y_day),axis=2)\n",
    "\n",
    "print(y_new.shape)\n",
    "print(y_new[7:7+162,0,4][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shuffle, y_shuffle = shuffle_in_unison(x1, y1)\n",
    "\n",
    "num_samples = x1.shape[0]\n",
    "num_val = int(num_samples*0.5)\n",
    "num_train = num_samples-num_val\n",
    "# train\n",
    "x_train, y_train = x_shuffle[:num_train], y_shuffle[:num_train]\n",
    "\n",
    "# val\n",
    "x_val, y_val = (\n",
    "    x_shuffle[num_train: num_train + num_val],\n",
    "    y_shuffle[num_train: num_train + num_val],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x:  (81, 7, 50, 5) y: (81, 4, 50, 1)\n",
      "val x:  (81, 7, 50, 5) y: (81, 4, 50, 1)\n",
      "test x:  (1, 7, 50, 5) y: (1, 4, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "for cat in [\"train\", \"val\", \"test\"]:\n",
    "    _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
    "    print(cat, \"x: \", _x.shape, \"y:\", _y.shape)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(\"week49/\", \"%s.npz\" % cat),\n",
    "        x=_x,\n",
    "        y=_y,\n",
    "        x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
    "        y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finish, and check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = np.absolute(y_test)\n",
    "difference[difference != difference] = 0\n",
    "mae = difference.mean()\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 62.15392087  68.0734889   66.26611642  90.99872745 192.        ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.abs(x_test[0,:,4,:]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407.0\n",
      "463.0\n",
      "469.0\n",
      "418.0\n",
      "405.0\n",
      "435.0\n",
      "693.0\n",
      "675.0\n",
      "706.0\n",
      "937.0\n",
      "962.0\n",
      "911.0\n",
      "913.0\n",
      "763.0\n",
      "815.0\n",
      "618.0\n",
      "691.0\n",
      "565.0\n",
      "532.0\n",
      "452.0\n",
      "389.0\n",
      "387.0\n",
      "316.0\n",
      "302.0\n",
      "292.0\n",
      "419.0\n",
      "444.0\n",
      "754.0\n"
     ]
    }
   ],
   "source": [
    "for i in range (28):\n",
    "    print(np.sum(groundtruth[7*i:7*(i+1),4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
